{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "ç†ç³»          3933\n",
       "èŠ¸èƒ½          3576\n",
       "é›‘å­¦          3203\n",
       "ã‚¹ãƒãƒ¼ãƒ„        3063\n",
       "æ–‡ç³»          3063\n",
       "ã‚¢ãƒ‹ãƒ¡ã‚²ãƒ¼ãƒ       2923\n",
       "Category       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../Data/Unprocess.csv\")\n",
    "# dfì˜ \"A\"ì—´ì´ '\\x0c'ì™€ ë‹¤ë¥¸ ê²ƒë§Œ ì €ì¥\n",
    "df = df[df[\"A\"] != '\\x0c']\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv(\"../Data/Unprocess.csv\", index=False)\n",
    "df.Category.value_counts()\n",
    "\n",
    "# ì—´ ë‚´ìš© ë³€ê²½ : 1. ã‚¢ãƒ‹ãƒ¡ã‚²ãŒã‚²ãƒ¼ãƒ  -> ã‚¢ãƒ‹ãƒ¡ã‚²ãƒ¼ãƒ  ë¡œ ë³€ê²½\n",
    "#               2. ã ã£ -> é›‘å­¦ìœ¼ë¡œ ë³€ê²½\n",
    "#               3. ãƒ¬ã¡ã§ -> ã‚¹ãƒãƒ¼ãƒ„ ë¡œ ë³€ê²½\n",
    "df = pd.read_csv(\"../Data/Unprocess.csv\")\n",
    "df.loc[df[\"Category\"] == \" ã‚¢ãƒ‹ãƒ¡ã‚²ãŒã‚²ãƒ¼ãƒ \", \"Category\"] = \"ã‚¢ãƒ‹ãƒ¡ã‚²ãƒ¼ãƒ \"\n",
    "df.loc[df[\"Category\"] == \"ã ã£\", \"Category\"] = \"é›‘å­¦\"\n",
    "df.loc[df[\"Category\"] == \"ãƒ¬ã¡ã§\", \"Category\"] = \"ã‚¹ãƒãƒ¼ãƒ„\"\n",
    "\n",
    "df.to_csv(\"../Data/Unprocess.csv\", index=False)\n",
    "df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•´ë‹¹ uniqueê°’ì„ ë°”íƒ•ìœ¼ë¡œ 6ê°œì˜ DFìƒì„± í›„ íŒŒì¼ë¡œ ì €ì¥\n",
    "for i in df.Category.unique():\n",
    "    df_temp = df[df[\"Category\"] == i]\n",
    "    df_temp.to_csv(f\"../Data/{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Korpora import Korpora\n",
    "from konlpy.tag import Okt\n",
    "# ì¼ë³¸ì–´ tokenize import\n",
    "from janome.tokenizer import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from joblib import dump\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genre = ['é›‘å­¦', 'ã‚¹ãƒãƒ¼ãƒ„', 'ç†ç³»', 'èŠ¸èƒ½', 'ã‚¢ãƒ‹ãƒ¡ã‚²ãƒ¼ãƒ ', 'æ–‡ç³»']\n",
    "\n",
    "for i in Genre:\n",
    "    df = pd.read_csv(f\"../Data/{i}.csv\", usecols =[\"Q\",\"K1\",\"K2\",\"K3\",\"K4\",\"A\"])\n",
    "\n",
    "    # ê° ì—´ì„ ë¬¸ìì—´ë¡œ í•©ì³ì„œ íŠœí”Œ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "    QnA = [(q + \":\" + k1 +\",\"+ k2 +\",\"+ k3 +\",\"+ k4, index, a) for index, q, k1, k2, k3, k4, a in zip(df.index, df['Q'], df['K1'], df['K2'], df['K3'], df['K4'], df[\"A\"])]\n",
    "\n",
    "    data = [(Question, index) for Question, index, Answer in QnA]\n",
    "    # í…ìŠ¤íŠ¸ ë²¡í„°í™”ì™€ ë¶„ë¥˜ ëª¨ë¸ì„ í¬í•¨í•œ íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "    model = make_pipeline(\n",
    "        TfidfVectorizer(),\n",
    "        MultinomialNB()\n",
    "    )\n",
    "    # ëª¨ë¸ í•™ìŠµ\n",
    "    X_train = [item[0] for item in data]\n",
    "    y_train = [item[1] for item in data]\n",
    "    model.fit(X_train, y_train)\n",
    "    # ëª¨ë¸ ì €ì¥\n",
    "    dump(model, f'../Model/sim_{i}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "from CRAWL import *\n",
    "import pandas as pd\n",
    "# ìœ ì‚¬ë„ ëª¨ë¸ ë¡œë“œ \n",
    "\n",
    "Genre_list = ['é›‘å­¦', 'ã‚¹ãƒãƒ¼ãƒ„', 'ç†ç³»', 'èŠ¸èƒ½', 'ã‚¢ãƒ‹ãƒ¡ã‚²ãƒ¼ãƒ ', 'æ–‡ç³»']\n",
    "# Genre ë‚´ìš©ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë³€ìˆ˜ 6ê°œë¥¼ ë§Œë“¤ê³ , ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "é›‘å­¦= load('../Model/sim_é›‘å­¦.joblib')\n",
    "ã‚¹ãƒãƒ¼ãƒ„ = load('../Model/sim_ã‚¹ãƒãƒ¼ãƒ„.joblib')\n",
    "ç†ç³» = load('../Model/sim_ç†ç³».joblib')\n",
    "èŠ¸èƒ½ = load('../Model/sim_èŠ¸èƒ½.joblib')\n",
    "ã‚¢ãƒ‹ãƒ¡ã‚²ãƒ¼ãƒ  = load('../Model/sim_ã‚¢ãƒ‹ãƒ¡ã‚²ãƒ¼ãƒ .joblib')\n",
    "æ–‡ç³» = load('../Model/sim_æ–‡ç³».joblib')\n",
    "Genre_model = [é›‘å­¦, ã‚¹ãƒãƒ¼ãƒ„, ç†ç³», èŠ¸èƒ½, ã‚¢ãƒ‹ãƒ¡ã‚²ãƒ¼ãƒ , æ–‡ç³»]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=0 # ë°ì´í„° ì¶”ê°€ ë³€ìˆ˜\n",
    "# í™”ë©´ í´ë¦­ í•¨ìˆ˜\n",
    "def click_answer(most_similar_index):\n",
    "    if most_similar_index==0 :\n",
    "        pyautogui.click(950, 980)  \n",
    "    elif most_similar_index==1:\n",
    "        pyautogui.click(950, 1110) \n",
    "    elif most_similar_index==2:\n",
    "        pyautogui.click(950, 1244)\n",
    "    elif most_similar_index==3:\n",
    "        pyautogui.click(950, 1363) \n",
    "        \n",
    "def find_answer_location(imgpath):\n",
    "    screenshot = np.array(pyautogui.screenshot())# ì „ì²´í™”ë©´ ìº¡ì²˜\n",
    "    gray = cv2.cvtColor(screenshot, cv2.COLOR_BGR2GRAY) # O.pngíƒìƒ‰\n",
    "    result = cv2.matchTemplate(gray, cv2.imread(imgpath, 0), cv2.TM_CCOEFF_NORMED)# ì´ë¯¸ì§€ ê²€ì¶œ\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)# ìµœëŒ€ê°’ ì°¾ê¸°\n",
    "    return max_loc     # ìµœëŒ€ê°’ ìœ„ì¹˜ ë°˜í™˜\n",
    "\n",
    "# ì •ë‹µ ì°¾ê¸°\n",
    "def find_answer():\n",
    "    # 1ì´ˆë™ì•ˆ ì‹¤í–‰í•˜ê¸°\n",
    "    for _ in range(5) :\n",
    "        x,y = find_answer_location('../Img/XX.png')\n",
    "        if 1050<=x<=1150 and 600<=y<=700:\n",
    "            x,y = find_answer_location('../Img/O.png')\n",
    "            if 940<=x<=1050 and 970<=y<=1094:\n",
    "                return 1\n",
    "            if 940<=x<=1050 and 1100<=y<=1210:\n",
    "                return 2\n",
    "            if 940<=x<=1050 and 1234<=y<=1341:\n",
    "                return 3\n",
    "            if 940<=x<=1050 and 1353<=y<=1484:\n",
    "                return 4\n",
    "        time.sleep(0.1)\n",
    "    return 0\n",
    "\n",
    "def levenshtein_distance(s1, s2):\n",
    "    m, n = len(s1), len(s2)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1]) + 1\n",
    "\n",
    "    return dp[m][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "1.æ—¥æœ¬ãƒ†ãƒ¬ãƒ“ã®ãƒãƒ©ã‚¨ãƒ†ã‚£ç•ªçµ„ã€ãªã‚“ã§ã‚‚ãƒ¯ãƒ¼ãƒ«ãƒ‰ãƒ©ãƒ³ã‚­ãƒ³ã‚° ãƒãƒ—&ã‚¤ãƒ¢ãƒˆã®ã€‡ã®ã€‡Oã€‡ã€ ã€‚ ã€‡ã®ã€‡ã®ã€‡ã¯ä½• ?:ä¸–ç•Œéšç´š,ä¸–ç•Œãƒ©ãƒ³ã‚¯,ä¸–ç•Œåºåˆ—,ä¸–ç•Œç•ªä»˜\n",
      "2.ãƒãƒ©ã‚¨ãƒ†ã‚£ç•ªçµ„ã€ãªã‚“ã§ã‚‚ãƒ¯ãƒ¼ãƒ«ãƒ‰ãƒ©ãƒ³ã‚­ãƒ³ã‚° ãƒãƒ—&ã€‡ã€‡ã€‡ã®ä¸–ç•Œç•ªä»˜ã€ã€‚ã€‡ã€‡ã€‡ã«å…¥ã‚‹åå‰ã¯ä½• ?\n",
      "==================================================\n",
      "â¡ï¸Vectorization :  ['ä¸–ç•Œç•ªä»˜', 'ã‚¤ãƒ¢ãƒˆ', 'ãƒ‡ã‚¬ãƒ¯', 'ã‚¢ãƒªãƒ¨ã‚·', 'ãƒ­ãƒ¼ãƒ•ãƒ©']\n",
      "ì •ë‹µ : 0 ğŸ¤©\n",
      "==================================================\n",
      "1.æ¼”åŠ‡ç”¨èªã§ã€é•·æœŸã«ã‚ãŸã£ã¦åŒã˜æ¼”ç›®ã‚’ä¸Šæ¼”ã™ã‚‹ã“ã¨ã‚’ä½•ã¨ã„ã† ?:ãƒŸãƒ‰ãƒ«ãƒ©ãƒ³,ã‚»ã‚«ãƒ³ãƒ‰ãƒ©ãƒ³,ã‚·ãƒ§ãƒ¼ãƒˆãƒ©ãƒ³,ãƒ­ãƒ³ã‚°ãƒ©ãƒ³\n",
      "2.æ¼”åŠ‡ç”¨èªã§ã€é•·æœŸã«ã‚ãŸã£ã¦åŒã˜æ¼”ç›®ã‚’ä¸Šæ¼”ã™ã‚‹ã“ã¨ã‚’ä½•ã¨ã„ã† ?\n",
      "==================================================\n",
      "ì •ë‹µ : 3 ğŸ¤©\n",
      "==================================================\n",
      "1.é™¸ä¸Šç«¶æŠ€ã‚„ãƒ†ã‚¹ãƒˆãªã©ã§æ™‚é–“ã‚’ã¯ã‹ã‚‹ãŸã‚ã®é“å…·ã¯ã€Œã€‡ã€‡ã€‡ã‚¦ã‚©ãƒƒãƒŠã€ã€‚ã€‡ã€‡ã€‡ã¯ä½• ?:ã‚¹ã‚­ãƒƒãƒ—,ã‚¹ãƒ†ãƒƒãƒ—,ã‚¹ãƒˆãƒƒãƒ—,ã‚¹ãƒªãƒƒãƒ—\n",
      "2.å®šåŠ›ã®å¼±ã„äººãŒç›®ã«è£…ç€ã™ã‚‹ã€ŒCã€‡C)ã€‡ã£ãƒ¬ãƒ³ã‚ºã€ã€‚ã€‡ã€‡ã€‡ã¯ä½• 2\n",
      "==================================================\n",
      "â¡ï¸Vectorization :  ['ã‚¹ãƒªãƒƒãƒ—', 'ã‚³ãƒ³ãƒãƒ‘ã‚¤ãƒ«', 'ã‚³ãƒ³ã‚¿ã‚¯ãƒˆ', 'ã‚³ãƒ³ã‚µãƒ¼ãƒˆ', 'ã‚³ãƒ³ãƒãƒ¼ãƒˆ']\n",
      "ì •ë‹µ : 1 ğŸ¤©\n",
      "==================================================\n",
      "1.é™¸å¥¥æ¹¾ã‚’éš”ã¦ã¦ä¸‹åŒ—äººé‚Šå³¶ã«å¯¾è²¡ã™ã‚‹ã€é’æ£®çœŒã®ç”Ÿå³¶ã¯ã©ã“2:æ´¥è»½ç”Ÿå³¶,ç´€ä¼Šç”Ÿå³¶,èƒ½ç™»ç”Ÿå³¶,æˆ¿ç·ç”Ÿå³¶\n",
      "2.æ¬¡ã®ã†ã¡ã€æ—¥æœ¬æµ·å´ã«ã‚ã‚‹ç”Ÿå³¶ã¯ã©ã‚Œ 2?\n",
      "==================================================\n",
      "â¡ï¸Vectorization :  ['æ´¥è»½ç”Ÿå³¶', 'èƒ½ç™»ç”Ÿå³¶', 'ç´€ä¼Šå¹´å³¶', 'æˆ¿ç·ç”Ÿå³¶', 'å¤§éšˆç”Ÿå³¶']\n",
      "ì •ë‹µ : 0 ğŸ¤©\n",
      "==================================================\n",
      "1.åˆ¥åã‚’ã€Œã‚¢ãƒ•ãƒªã‚«ã‚¹ãƒŸãƒ¬ã€ã¨ã„ã†ã€ã‚¢ãƒ«ãƒ—ãƒ WmESã€ãƒ«ãƒ’ã‚¹ã«ã‚´ãƒ‹ãƒ§ã¨ 0:ãƒãƒ³ãƒˆãƒãƒ¼ãƒªã‚¢,ãƒ’ãƒ£ã‚¯ãƒˆãƒãƒœãƒ¼ãƒªã‚¢,ã‚»ãƒ³ãƒˆãƒãƒ¼ãƒªã‚¢,ã‚¸ãƒ¥ã‚¦ãƒˆãƒãƒ¼ãƒªã‚¢\n",
      "2.åˆ¥åã‚’ã€Œã‚¢ãƒ•ãƒªã‚«ã‚¹ãƒŸãƒ¬ã€ã¨ã„ã†ã€ã‚¢ãƒ«ãƒ—ãƒ WmESã€ãƒ«ãƒ’ã‚¹ã«ã‚´ãƒ‹ãƒ§ã¨ 0\n",
      "==================================================\n",
      "ì •ë‹µ : 2 ğŸ¤©\n",
      "==================================================\n",
      "1.ã‚¹ã‚¤ã‚¹ã®ãƒ•ã‚§ãƒ‡ãƒ©ãƒ¼ã¨ã„ãˆã°ã€ã©ã‚“ãªã‚¹ãƒãƒ¼ãƒ„ã§æ´»èºã—ãŸç”·æ€§?:ã‚µãƒƒã‚«ãƒ¼,ãƒ†ãƒ‹ã‚¹,ã‚´ãƒ«ãƒ•,ãƒœã‚¯ã‚·ãƒ³ã‚°\n",
      "2.ã€Œtotoã€ã¨ã„ãˆã°ã€ã©ã‚“ãªã‚¹ãƒãƒ¼ãƒ„ã«é–¢ã™ã‚‹ãã˜ ?\n",
      "==================================================\n",
      "â¡ï¸Vectorization :  ['ãƒ†ãƒ‹ã‚¹', 'é‡çƒ', 'ã‚µãƒƒã‚«ãƒ¼', 'ãƒœã‚¯ã‚·ãƒ³ã‚°', 'ã‚´ãƒ«ãƒ•']\n",
      "ì •ë‹µ : 0 ğŸ¤©\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "' ã‚¢ãƒ‹ãƒ¡ã‚²ãƒ¼ãƒ ' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Genre\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ã‚¢ãƒ‹ãƒ¡ã‚²ãŒã‚²ãƒ¼ãƒ \u001b[39m\u001b[38;5;124m\"\u001b[39m : Genre\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mã‚¢ãƒ‹ãƒ¡ã‚²ãƒ¼ãƒ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Genre\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mèŒèƒ½\u001b[39m\u001b[38;5;124m\"\u001b[39m : Genre\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mèŠ¸èƒ½\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m model_index\u001b[38;5;241m=\u001b[39m \u001b[43mGenre_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGenre\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m Genre_model[model_index]\n\u001b[0;32m     14\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGenre\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,usecols \u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: ' ã‚¢ãƒ‹ãƒ¡ã‚²ãƒ¼ãƒ ' is not in list"
     ]
    }
   ],
   "source": [
    "mismatch = pd.read_csv('data.csv')\n",
    "# ë¬¸ì œ ë§ì¶”ê¸° ì‹œì‘\n",
    "while True:\n",
    "    txt_list = capture_screen()\n",
    "    if len(txt_list)<5:\n",
    "        print(\"ì„ ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        break\n",
    "    Question, Genre, Nominee = extract(txt_list)\n",
    "    if Genre==\"ã ã£\" : Genre=\"é›‘å­¦\"\n",
    "    if Genre==\" ã‚¢ãƒ‹ãƒ¡ã‚²ãŒã‚²ãƒ¼ãƒ \" : Genre=\"ã‚¢ãƒ‹ãƒ¡ã‚²ãƒ¼ãƒ \"\n",
    "    if Genre==\"èŒèƒ½\" : Genre=\"èŠ¸èƒ½\"\n",
    "    model_index= Genre_list.index(Genre)\n",
    "    model = Genre_model[model_index]\n",
    "    df = pd.read_csv(f\"../Data/{Genre}.csv\",usecols =[\"Q\",\"K1\",\"K2\",\"K3\",\"K4\",\"A\"])\n",
    "    # ê° ì—´ì„ ë¬¸ìì—´ë¡œ í•©ì³ì„œ íŠœí”Œ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "    QnA = [(q + \":\" + k1 +\",\"+ k2 +\",\"+ k3 +\",\"+ k4, index, a) for index, q, k1, k2, k3, k4, a in zip(df.index, df['Q'], df['K1'], df['K2'], df['K3'], df['K4'], df[\"A\"])]\n",
    "\n",
    "    # ì…ë ¥ ë¬¸ì¥ì„ ì˜ˆì¸¡\n",
    "    input_text =\",\".join((Question, Nominee[0], Nominee[1], Nominee[2], Nominee[3]))\n",
    "    predicted_label = model.predict([input_text])[0]    \n",
    "    print(f\"{'='*50}\\n1.{QnA[predicted_label][0]}\")\n",
    "    print(f\"2.{Question}\\n{'='*50}\")\n",
    "    \n",
    "    # ì˜ˆì¸¡ëœ ë ˆì´ë¸”ì— í•´ë‹¹í•˜ëŠ” ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°\n",
    "    predicted_question = QnA[predicted_label][2]\n",
    "\n",
    "    if QnA[predicted_label][2] in Nominee:\n",
    "        most_similar_index = Nominee.index(QnA[predicted_label][2])\n",
    "    else :\n",
    "        # ë¬¸ì¥ ë²¡í„°í™”\n",
    "        try:\n",
    "            distances = [levenshtein_distance(predicted_question, text) for text in Nominee]\n",
    "            # ê°€ì¥ ìœ ì‚¬í•œ ë‹¨ì–´ ì¶”ì¶œ\n",
    "            most_similar_index = distances.index(min(distances))\n",
    "            print(\"â¡ï¸Vectorization : \",[predicted_question] + [nominee for nominee in Nominee])\n",
    "\n",
    "        except:\n",
    "            most_similar_index = 0\n",
    "    # ê²°ê³¼ ì¶œë ¥ & í´ë¦­\n",
    "    print(\"ì •ë‹µ :\", most_similar_index,\"ğŸ¤©\")\n",
    "    click_answer(most_similar_index)\n",
    "    answer_num=find_answer()\n",
    "    if answer_num : # ë¬¸ì œë¥¼ í‹€ë ¸ë‹¤ë©´\n",
    "        answer=Nominee[answer_num-1]\n",
    "        mismatch.loc[len(df)] = [Question, Genre, Nominee[0], Nominee[1], Nominee[2], Nominee[3], answer]\n",
    "        mismatch.to_csv('data.csv', index=False)\n",
    "    time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ã‹ãã‚Œã‚“ã°ã¼'ì™€ ê°€ì¥ ë¹„ìŠ·í•œ ë‹¨ì–´ëŠ” 'ã‹ãã‚Œã‚“ã¼'ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ì…ë ¥ ë°ì´í„°\n",
    "texts = ['ãŠã«ã”ã£ã“', 'ã‹ãã‚Œã‚“ã¼', 'ã‹ã‘ã£ã“', 'ã•ã‹ã‚ãŒã‚Š']\n",
    "\n",
    "# ì…ë ¥ ë‹¨ì–´\n",
    "input_text = 'ã‹ãã‚Œã‚“ã°ã¼'\n",
    "\n",
    "# ë ˆë²¤ìŠˆíƒ€ì¸ ê±°ë¦¬ ê³„ì‚°\n",
    "distances = [levenshtein_distance(input_text, text) for text in texts]\n",
    "\n",
    "# ê°€ì¥ ìœ ì‚¬í•œ ë‹¨ì–´ ì¶”ì¶œ\n",
    "most_similar_index = distances.index(min(distances))\n",
    "most_similar_word = texts[most_similar_index]\n",
    "\n",
    "print(f\"'{input_text}'ì™€ ê°€ì¥ ë¹„ìŠ·í•œ ë‹¨ì–´ëŠ” '{most_similar_word}'ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "# ìµœì†Œ í¸ì§‘ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ëŠ” ë ˆë²¤ìŠˆíƒ€ì¸ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
