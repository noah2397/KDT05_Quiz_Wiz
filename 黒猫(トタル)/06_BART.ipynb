{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb61086a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>写真帳」を英語でいうと何 ?? : 1.loose leaf, 2.account book...</td>\n",
       "      <td>album</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>鮭の内臓をとって、塩漬けにしたものを何という ?? : 1.さらまき鮭, 2.はらまき鮭, ...</td>\n",
       "      <td>あらまき鮭</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>次のうち、約21kmの距離で行われるマラソン競技はどれ ?  _? : 1.フルマフソン, ...</td>\n",
       "      <td>ハーフマラフソン</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>秘の暑い時に、風を起こすために用いるものはどれ ?2? : 1.うちきさ, 2.うちわ, 3...</td>\n",
       "      <td>うちわ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>関門海峡を挟んで九州と面している山口県の都市はどこ ?? : 1.上関市, 2.下関市, 3...</td>\n",
       "      <td>下関市</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22555</th>\n",
       "      <td>石田スイの漫画『東京喰種トーキョーグール』の舞台となっている国はとどこ?? : 1.オースト...</td>\n",
       "      <td>日本</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22556</th>\n",
       "      <td>フジテレビのクイズ番組『ネプリーグ』」のボーナスステージといえば「何アドベンチャー」 2? ...</td>\n",
       "      <td>トロッコ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22557</th>\n",
       "      <td>エアラインといえば、何の会証 ?? : 1.鉄道会計, 2.タクシー会視, 3.航空会計,...</td>\n",
       "      <td>航空会計</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22558</th>\n",
       "      <td>長崎に鳴滝塾を開いたシーボルトは円の         ーー? : 1.中国人, 2.ドイツ人...</td>\n",
       "      <td>ドイツ人</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22559</th>\n",
       "      <td>「ヤバT」の略称で呼ばれるバンドは何2? : 1.Kind Gnu, 2.ヤバイTシャツ屋さ...</td>\n",
       "      <td>ヤバイTシャツ屋さん</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22560 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  prediction\n",
       "0      写真帳」を英語でいうと何 ?? : 1.loose leaf, 2.account book...       album\n",
       "1      鮭の内臓をとって、塩漬けにしたものを何という ?? : 1.さらまき鮭, 2.はらまき鮭, ...       あらまき鮭\n",
       "2      次のうち、約21kmの距離で行われるマラソン競技はどれ ?  _? : 1.フルマフソン, ...    ハーフマラフソン\n",
       "3      秘の暑い時に、風を起こすために用いるものはどれ ?2? : 1.うちきさ, 2.うちわ, 3...         うちわ\n",
       "4      関門海峡を挟んで九州と面している山口県の都市はどこ ?? : 1.上関市, 2.下関市, 3...         下関市\n",
       "...                                                  ...         ...\n",
       "22555  石田スイの漫画『東京喰種トーキョーグール』の舞台となっている国はとどこ?? : 1.オースト...          日本\n",
       "22556  フジテレビのクイズ番組『ネプリーグ』」のボーナスステージといえば「何アドベンチャー」 2? ...        トロッコ\n",
       "22557  \n",
       "エアラインといえば、何の会証 ?? : 1.鉄道会計, 2.タクシー会視, 3.航空会計,...        航空会計\n",
       "22558  長崎に鳴滝塾を開いたシーボルトは円の         ーー? : 1.中国人, 2.ドイツ人...        ドイツ人\n",
       "22559  「ヤバT」の略称で呼ばれるバンドは何2? : 1.Kind Gnu, 2.ヤバイTシャツ屋さ...  ヤバイTシャツ屋さん\n",
       "\n",
       "[22560 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"./Data/Low2.csv\")\n",
    "df\n",
    "# 열 Q, K1, K2, K3, K4의 내용을 합쳐서 하나의 열로 합치기\n",
    "df['QK'] = df['Q'] +\"? : 1.\"+ df['K1'] +\", 2.\"+  df['K2'] + \", 3.\"+ df['K3'] +\", 4.\"+  df['K4']\n",
    "df=df[['QK','A']]\n",
    "#열 이름을 text, prediction으로 고치기\n",
    "df.columns=['text','prediction']\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a583dd-df09-42a4-bed9-cbe3270fd368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source News : 次のうち、空気中で最も速く移動すとで/ぁ】ち円肝/? : 1.イチローのバックホーム, 2.リニアモーターカー, 3.光, 4.と=コ\n",
      "四\n",
      "Summarization : 光\n",
      "Training Data Size : 22334\n",
      "Validation Data Size : 203\n",
      "Testing Data Size : 23\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "train, valid, test = np.split(\n",
    "    df.sample(frac=1, random_state=42), [int(0.99 * len(df)), int(0.999 * len(df))]\n",
    ")\n",
    "\n",
    "print(f\"Source News : {train.text.iloc[0][:200]}\")\n",
    "print(f\"Summarization : {train.prediction.iloc[0][:50]}\")\n",
    "print(f\"Training Data Size : {len(train)}\")\n",
    "print(f\"Validation Data Size : {len(valid)}\")\n",
    "print(f\"Testing Data Size : {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a66d8a-bb12-4b74-9ea7-529192ee562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([    0, 37127, 11582,  5543, 48018, 48718, 46311,  5543, 47341, 36714,\n",
      "        15375,  3070, 48570,  6800, 47643, 48190, 44636,  7471, 48885, 48173,\n",
      "         4333, 49040, 36714,  6248,  2023, 48675, 15722, 48735, 48281, 48190,\n",
      "           73, 46311, 10172, 49287, 46311,  5543, 48745, 27819, 36484,  9264,\n",
      "           46, 29482,  4832,   112,     4, 48611, 49511, 49323, 48438, 48018,\n",
      "        49441, 49574, 48909,  3726, 48943, 21402,     6,   132,     4, 48947,\n",
      "        49464, 49017, 49768, 48438, 49343, 48438, 49063, 48438,     6,   155,\n",
      "            4, 49500,     6,   204,     4, 48281,  5214, 49195, 50121, 50118,\n",
      "        47516,  3726,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1], device='cuda:0'), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0], device='cuda:0'), tensor([    0, 49500,     2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100], device='cuda:0')) cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BartTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def make_dataset(data, tokenizer, device):\n",
    "    tokenized = tokenizer(\n",
    "        text=data.text.tolist(),\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    labels = []\n",
    "    input_ids = tokenized[\"input_ids\"].to(device)\n",
    "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
    "    for target in data.prediction:\n",
    "        labels.append(tokenizer.encode(target, return_tensors=\"pt\").squeeze())\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=-100).to(device)\n",
    "    return TensorDataset(input_ids, attention_mask, labels)\n",
    "\n",
    "\n",
    "\n",
    "def get_datalodader(dataset, sampler, batch_size):\n",
    "    data_sampler = sampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler=data_sampler, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = BartTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"facebook/bart-base\"\n",
    ")\n",
    "\n",
    "train_dataset = make_dataset(train, tokenizer, device)\n",
    "train_dataloader = get_datalodader(train_dataset, RandomSampler, batch_size)\n",
    "\n",
    "valid_dataset = make_dataset(valid, tokenizer, device)\n",
    "valid_dataloader = get_datalodader(valid_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "test_dataset = make_dataset(test, tokenizer, device)\n",
    "test_dataloader = get_datalodader(test_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "print(train_dataset[0], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b5a022-ff45-4824-846e-5b1193862b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"facebook/bart-base\"\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(\"./Model/Bart.pt\"))\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b1e482e-5eb8-416f-a228-56788c328440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "└ shared\n",
      "└ encoder\n",
      "│  └ embed_tokens\n",
      "│  └ embed_positions\n",
      "│  └ layers\n",
      "│  │  └ 0\n",
      "│  │  └ 1\n",
      "│  │  └ 2\n",
      "│  │  └ 3\n",
      "│  │  └ 4\n",
      "│  │  └ 5\n",
      "│  └ layernorm_embedding\n",
      "└ decoder\n",
      "│  └ embed_tokens\n",
      "│  └ embed_positions\n",
      "│  └ layers\n",
      "│  │  └ 0\n",
      "│  │  └ 1\n",
      "│  │  └ 2\n",
      "│  │  └ 3\n",
      "│  │  └ 4\n",
      "│  │  └ 5\n",
      "│  └ layernorm_embedding\n",
      "lm_head\n"
     ]
    }
   ],
   "source": [
    "for main_name, main_module in model.named_children():\n",
    "    print(main_name)\n",
    "    for sub_name, sub_module in main_module.named_children():\n",
    "        print(\"└\", sub_name)\n",
    "        for ssub_name, ssub_module in sub_module.named_children():\n",
    "            print(\"│  └\", ssub_name)\n",
    "            for sssub_name, sssub_module in ssub_module.named_children():\n",
    "                print(\"│  │  └\", sssub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ad80cc-c0c2-4b03-9ab1-8fa50898ca62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2792 [00:00<?, ?it/s]C:\\Users\\mathn\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\bart\\modeling_bart.py:587: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Training: 100%|██████████| 2792/2792 [13:39<00:00,  3.41it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:06<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.8143 Val Loss: 0.6997 Val Rouge 0.0000\n",
      "Saved the model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2792/2792 [13:29<00:00,  3.45it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:05<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.8150 Val Loss: 0.6997 Val Rouge 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2792/2792 [13:29<00:00,  3.45it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:05<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.8143 Val Loss: 0.6997 Val Rouge 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2792/2792 [13:29<00:00,  3.45it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:05<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.8163 Val Loss: 0.6997 Val Rouge 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2792/2792 [13:29<00:00,  3.45it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:05<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.8095 Val Loss: 0.6997 Val Rouge 0.0000\n",
      "Saved the model weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2792/2792 [13:29<00:00,  3.45it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:05<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.8145 Val Loss: 0.6997 Val Rouge 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2792/2792 [13:29<00:00,  3.45it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:05<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.8153 Val Loss: 0.6997 Val Rouge 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2792/2792 [13:30<00:00,  3.44it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:05<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.8144 Val Loss: 0.6997 Val Rouge 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2792/2792 [13:30<00:00,  3.45it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.8127 Val Loss: 0.6997 Val Rouge 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2792/2792 [13:30<00:00,  3.45it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:05<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.8128 Val Loss: 0.6997 Val Rouge 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2792/2792 [13:30<00:00,  3.44it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:05<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.8172 Val Loss: 0.6997 Val Rouge 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2792/2792 [13:30<00:00,  3.44it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:05<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 0.8153 Val Loss: 0.6997 Val Rouge 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2792/2792 [13:31<00:00,  3.44it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:05<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 0.8130 Val Loss: 0.6997 Val Rouge 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2792/2792 [13:30<00:00,  3.44it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:05<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 0.8170 Val Loss: 0.6997 Val Rouge 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2792/2792 [13:31<00:00,  3.44it/s]\n",
      "Evaluation: 100%|██████████| 26/26 [00:05<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss: 0.8153 Val Loss: 0.6997 Val Rouge 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 331/2792 [01:37<12:07,  3.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 68\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m evaluation(model, valid_dataloader)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Val Rouge \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, dataloader)\u001b[0m\n\u001b[0;32m     22\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids, attention_mask, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 25\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     28\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\mathn\\.conda\\envs\\Quick\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mathn\\.conda\\envs\\Quick\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1728\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1724\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1725\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1726\u001b[0m         )\n\u001b[1;32m-> 1728\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1746\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1747\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m lm_logits \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\u001b[38;5;241m.\u001b[39mto(lm_logits\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\mathn\\.conda\\envs\\Quick\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mathn\\.conda\\envs\\Quick\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1614\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1607\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[0;32m   1608\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   1609\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1610\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1611\u001b[0m     )\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1614\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1623\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1624\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[0;32m   1630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[1;32mc:\\Users\\mathn\\.conda\\envs\\Quick\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mathn\\.conda\\envs\\Quick\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1400\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1395\u001b[0m     encoder_attention_mask \u001b[38;5;241m=\u001b[39m encoder_attention_mask \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m encoder_attention_mask \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_sdpa \u001b[38;5;129;01mand\u001b[39;00m cross_attn_head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[0;32m   1397\u001b[0m     \u001b[38;5;66;03m# output_attentions=True & cross_attn_head_mask can not be supported when using SDPA, and we fall back on\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m     \u001b[38;5;66;03m# the manual implementation that requires a 4D causal mask in all cases.\u001b[39;00m\n\u001b[0;32m   1399\u001b[0m     \u001b[38;5;66;03m# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\u001b[39;00m\n\u001b[1;32m-> 1400\u001b[0m     encoder_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_4d_attention_mask_for_sdpa\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1406\u001b[0m     \u001b[38;5;66;03m# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m     encoder_attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_attention_mask(\n\u001b[0;32m   1408\u001b[0m         encoder_attention_mask, inputs_embeds\u001b[38;5;241m.\u001b[39mdtype, tgt_len\u001b[38;5;241m=\u001b[39minput_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1409\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\modeling_attn_mask_utils.py:448\u001b[0m, in \u001b[0;36m_prepare_4d_attention_mask_for_sdpa\u001b[1;34m(mask, dtype, tgt_len)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;66;03m# torch.jit.trace, symbolic_trace and torchdynamo with fullgraph=True are unable to capture the controlflow `is_causal=attention_mask is None and q_len > 1`\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;66;03m# used as an SDPA argument. We keep compatibility with these tracing tools by always using SDPA's `attn_mask` argument in case we are tracing.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;66;03m# TODO: For dynamo, rather use a check on fullgraph=True once this is possible (https://github.com/pytorch/pytorch/pull/120400).\u001b[39;00m\n\u001b[0;32m    442\u001b[0m is_tracing \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    443\u001b[0m     torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing()\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask, torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mProxy)\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(torch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_dynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mis_compiling())\n\u001b[0;32m    446\u001b[0m )\n\u001b[1;32m--> 448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_tracing:\n\u001b[0;32m    450\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import gc  # gc 패키지 임포트\n",
    "\n",
    "def calc_rouge(preds, labels):\n",
    "    preds = preds.argmax(axis=-1)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    rouge2 = rouge_score.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=decoded_labels\n",
    "    )\n",
    "    return rouge2[\"rouge2\"]\n",
    "\n",
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for input_ids, attention_mask, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # GPU 캐시 비우기\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    return train_loss\n",
    "\n",
    "def evaluation(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss, val_rouge = 0.0, 0.0\n",
    "\n",
    "        for input_ids, attention_mask, labels in tqdm(dataloader, desc=\"Evaluation\"):\n",
    "            outputs = model(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "            loss = outputs.loss\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = labels.to(\"cpu\").numpy()\n",
    "            rouge = calc_rouge(logits, label_ids)\n",
    "            \n",
    "            val_loss += loss\n",
    "            val_rouge += rouge\n",
    "\n",
    "        val_loss = val_loss / len(dataloader)\n",
    "        val_rouge = val_rouge / len(dataloader)\n",
    "        return val_loss, val_rouge\n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\", tokenizer=tokenizer)\n",
    "best_loss = 10000\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, train_dataloader)\n",
    "    val_loss, val_accuracy = evaluation(model, valid_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f} Val Rouge {val_accuracy:.4f}\")\n",
    "\n",
    "    if train_loss < best_loss:\n",
    "        best_loss = train_loss\n",
    "        torch.save(model.state_dict(), \"./Model/Bart.pt\")\n",
    "        print(\"Saved the model weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bba9f3e-f939-4e77-b533-512c84921577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 2/2 [00:00<00:00,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 0.5255\n",
      "Test ROUGE-2 Score : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"facebook/bart-base\"\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(\"./Model/Bart.pt\"))\n",
    "\n",
    "test_loss, test_rouge_score = evaluation(model, test_dataloader)\n",
    "print(f\"Test Loss : {test_loss:.4f}\")\n",
    "print(f\"Test ROUGE-2 Score : {test_rouge_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c52711ca-faaa-489b-8f2d-4cf0780a2228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답 요약문 : 赤毛のアン\n",
      "모델 요약문 :  2.白毛のアン\n",
      "\n",
      "정답 요약문 : もののけ姫\n",
      "모델 요약문 :  2.在成紳合戦ぼんぼこ\n",
      "\n",
      "정답 요약문 : チョウ\n",
      "모델 요약문 : 2.コオロギ, 3.ホタル\n",
      "\n",
      "정답 요약문 : 和仁\n",
      "に コ\n",
      "모델 요약문 :  1.和仁\n",
      "に コ\n",
      "\n",
      "정답 요약문 : 新世紀エヴァンゲリオン\n",
      "모델 요약문 : 2.宇宙戦艦マト\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "summarizer = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=54,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "for index in range(2000,2005):\n",
    "    news_text = df.text.iloc[index]\n",
    "    summarization = df.prediction.iloc[index]\n",
    "    predicted_summarization = summarizer(news_text)[0][\"summary_text\"]\n",
    "    print(f\"정답 요약문 : {summarization}\")\n",
    "    print(f\"모델 요약문 : {predicted_summarization}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b251ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
